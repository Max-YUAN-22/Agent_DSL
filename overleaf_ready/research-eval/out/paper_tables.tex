% Auto-generated by research-eval/scripts/analyze_results.py
\begin{table}[htbp]
\caption{Real-World Performance Comparison (Auto-generated)}
\label{tab:rw_perf_auto}
\centering
\begin{tabular}{@{}lcc@{}}
\toprule
Framework & Throughput (tasks/sec) & Avg Latency (ms) \\
\midrule
Our DSL & 3822.040 & 0.30 \\
AutoGen & 1.803 & 554.57 \\
CrewAI & 1.655 & 604.27 \\
LangChain & 1.984 & 504.01 \\
\bottomrule
\end{tabular}
\end{table}